{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 누락 데이터 처리\n",
    "* 데이터의 품질을 높이기 위해서는 누락 데이터, 중복 데이터 등 오류를 수정하고 분석 목적에 맞게 변형하는 과정이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락 데이터 확인\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# info() 메소드로 데이터프레임의 요약 정보를 출력하면 각 열에 속하는 데이터 중에서 유효한 값의 개수를 보여준다.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'deck' 열에는 203개의 유효한 범주형 데이터가 있다. 따라서 'deck' 열에 있는 누락 데이터가 688개라는 사실을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    688\n",
      "C       59\n",
      "B       47\n",
      "D       33\n",
      "E       32\n",
      "A       15\n",
      "F       13\n",
      "G        4\n",
      "Name: deck, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# deck 열의 NaN 개수 계산하기\n",
    "# 이때 누락 데이터의 개수를 확인하려면 반드시 dropna=False 옵션을 사용한다.\n",
    "nan_deck = df['deck'].value_counts(dropna=False)\n",
    "print(nan_deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n"
     ]
    }
   ],
   "source": [
    "# isnull() 메소드로 누락 데이터 찾기\n",
    "print(df.head().isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   sex   age  sibsp  parch  fare  embarked  class   who  \\\n",
      "0      True    True  True  True   True   True  True      True   True  True   \n",
      "1      True    True  True  True   True   True  True      True   True  True   \n",
      "2      True    True  True  True   True   True  True      True   True  True   \n",
      "3      True    True  True  True   True   True  True      True   True  True   \n",
      "4      True    True  True  True   True   True  True      True   True  True   \n",
      "\n",
      "   adult_male   deck  embark_town  alive  alone  \n",
      "0        True  False         True   True   True  \n",
      "1        True   True         True   True   True  \n",
      "2        True  False         True   True   True  \n",
      "3        True   True         True   True   True  \n",
      "4        True  False         True   True   True  \n"
     ]
    }
   ],
   "source": [
    "# notnull() 메소드로 누락 데이터 찾기\n",
    "print(df.head().notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           3\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# isnull() 메소드로 누락 데이터 개수 구하기\n",
    "print(df.head().isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* isnull(): 누락 데이터면 True를 반환하고, 유효한 데이터가 존재하면 False를 반환한다.\n",
    "* notnull(): 유효한 데이터가 존재하면 True를 반환하고, 누락 데이터면 False를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived :  0\n",
      "pclass :  0\n",
      "sex :  0\n",
      "age :  177\n",
      "sibsp :  0\n",
      "parch :  0\n",
      "fare :  0\n",
      "embarked :  2\n",
      "class :  0\n",
      "who :  0\n",
      "adult_male :  0\n",
      "deck :  688\n",
      "embark_town :  2\n",
      "alive :  0\n",
      "alone :  0\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 제거\n",
    "# 열을 삭제하면 분석 대상이 갖는 특성(변수)을 제거하고, 행을 삭제하면 분석 대상의 관측값(레코드)을 제거하게 된다.\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "missing_df = df.isnull()\n",
    "for col in missing_df.columns:\n",
    "    missing_count = missing_df[col].value_counts()    # 각 열의 NaN 개수 파악\n",
    "    try:\n",
    "        print(col, \": \", missing_count[True])    # NaN 값이 있으면 개수 출력\n",
    "    except:\n",
    "        print(col, \": \", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive',\n",
      "       'alone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# NaN 값이 500개 이상인 열을 모두 삭제 - deck 열(891개 중 688개의 NaN 값)\n",
    "df_thresh = df.dropna(axis=1, thresh=500)\n",
    "print(df_thresh.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "# 기본값으로 how='any' 옵션이 적용되는데, NaN 값이 하나라도 존재하면 삭제한다.\n",
    "# how='all' 옵션으로 입력하면 모든 데이터가 NaN 값일 경우에만 삭제가 된다.\n",
    "df_age = df.dropna(subset=['age'], how='any', axis=0)\n",
    "print(len(df_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.0\n",
      "1    38.0\n",
      "2    26.0\n",
      "3    35.0\n",
      "4    35.0\n",
      "5     NaN\n",
      "6    54.0\n",
      "7     2.0\n",
      "8    27.0\n",
      "9    14.0\n",
      "Name: age, dtype: float64\n",
      "\n",
      "\n",
      "0    22.000000\n",
      "1    38.000000\n",
      "2    26.000000\n",
      "3    35.000000\n",
      "4    35.000000\n",
      "5    29.699118\n",
      "6    54.000000\n",
      "7     2.000000\n",
      "8    27.000000\n",
      "9    14.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 누락 데이터 치환\n",
    "# 승객의 나이 데이터가 누락된 행을 제거하지 않고, 'age' 열의 나머지 승객의 평균나이로 치환한다.\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['age'].head(10))\n",
    "print('\\n')\n",
    "\n",
    "mean_age = df['age'].mean(axis=0)\n",
    "df['age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "print(df['age'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "Southampton\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 가장 많이 나타나는 값으로 바꾸기\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "# idxmax() 메소드는 최대값을 가지는 인덱스 레이블을 출력한다.\n",
    "most_freq = df['embark_town'].value_counts(dropna=True).idxmax()\n",
    "print(most_freq)\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(most_freq, inplace=True)\n",
    "\n",
    "# embark_town 열 829행의 NaN 데이터 출력(NaN 값이 most_freq 값으로 대체)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "Name: embark_town, dtype: object\n",
      "\n",
      "\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829     Queenstown\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 이웃하고 있는 값으로 바꾸기\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df['embark_town'][825:830])\n",
    "print('\\n')\n",
    "\n",
    "df['embark_town'].fillna(method='ffill', inplace=True)\n",
    "print(df['embark_town'][825:830])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fillna() 메소드에 method='ffill' 옵션을 추가하면 NaN이 있는 행의 직전 행에 있는 값으로 바꿔준다.\n",
    "* method='bfill' 옵션을 사용하면 NaN이 있는 행의 바로 다음 행에 있는 값을 가지고 치환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 중복 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 확인\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1':['a','a','b','a','b'],\n",
    "                   'c2':[1,1,1,2,2],\n",
    "                   'c3':[1,1,2,2,2]})\n",
    "\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임 전체 행 데이터 중에서 중복값 찾기\n",
    "# 데이터프레임에 duplicated() 메소드를 적용하면 각 행의 중복 여부를 나타내는 불린 시리즈를 반환한다.\n",
    "df_dup = df.duplicated()\n",
    "print(df_dup)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "Name: c2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임의 특정 열 데이터에서 중복값 찾기\n",
    "# 1이 처음 나타난 0행과 2가 처음 나타난 3행을 제외하고 나머지 1,2,4행은 이전에 나온 행과 중복되므로 True가 된다.\n",
    "col_dup = df['c2'].duplicated()\n",
    "print(col_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "1  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n",
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n",
      "4  b   2   2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 중복 데이터 제거\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'c1':['a','a','b','a','b'],\n",
    "                   'c2':[1,1,1,2,2],\n",
    "                   'c3':[1,1,2,2,2]})\n",
    "print(df)\n",
    "print('\\n')\n",
    "\n",
    "# 데이터프레임에서 중복 행 제거\n",
    "df2 = df.drop_duplicates()\n",
    "print(df2)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  c1  c2  c3\n",
      "0  a   1   1\n",
      "2  b   1   2\n",
      "3  a   2   2\n"
     ]
    }
   ],
   "source": [
    "# c2, c3열을 기준으로 중복 행 제거\n",
    "df3 = df.drop_duplicates(subset=['c2','c3'])\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. 단위 환산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name       kpl  \n",
      "0       1  chevrolet chevelle malibu  7.652571  \n",
      "1       1          buick skylark 320  6.377143  \n",
      "2       1         plymouth satellite  7.652571  \n",
      "\n",
      "\n",
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0      130.0  3504.0          12.0          70   \n",
      "1  15.0          8         350.0      165.0  3693.0          11.5          70   \n",
      "2  18.0          8         318.0      150.0  3436.0          11.0          70   \n",
      "\n",
      "   origin                       name   kpl  \n",
      "0       1  chevrolet chevelle malibu  7.65  \n",
      "1       1          buick skylark 320  6.38  \n",
      "2       1         plymouth satellite  7.65  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# mpg(mile per gallon)를 kpl(kilometer per liter)로 변환(mpg_to_kpl=0.425)\n",
    "mpg_to_kpl = 1.60934/3.78541\n",
    "\n",
    "# mpg 열에 0.425를 곱한 결과를 새로운 열(kpl)에 추가\n",
    "df['kpl'] = df['mpg']*mpg_to_kpl\n",
    "print(df.head(3))\n",
    "print('\\n')\n",
    "\n",
    "# kpl 열을 소수점 아래 둘째자리에서 반올림\n",
    "df['kpl'] = df['kpl'].round(2)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. 자료형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower       object\n",
      "weight          float64\n",
      "acceleration    float64\n",
      "model year        int64\n",
      "origin            int64\n",
      "name             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 숫자가 문자열(object)로 저장된 경우에 숫자형(int 또는 float)으로 변환해야 한다.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['130.0' '165.0' '150.0' '140.0' '198.0' '220.0' '215.0' '225.0' '190.0'\n",
      " '170.0' '160.0' '95.00' '97.00' '85.00' '88.00' '46.00' '87.00' '90.00'\n",
      " '113.0' '200.0' '210.0' '193.0' '?' '100.0' '105.0' '175.0' '153.0'\n",
      " '180.0' '110.0' '72.00' '86.00' '70.00' '76.00' '65.00' '69.00' '60.00'\n",
      " '80.00' '54.00' '208.0' '155.0' '112.0' '92.00' '145.0' '137.0' '158.0'\n",
      " '167.0' '94.00' '107.0' '230.0' '49.00' '75.00' '91.00' '122.0' '67.00'\n",
      " '83.00' '78.00' '52.00' '61.00' '93.00' '148.0' '129.0' '96.00' '71.00'\n",
      " '98.00' '115.0' '53.00' '81.00' '79.00' '120.0' '152.0' '102.0' '108.0'\n",
      " '68.00' '58.00' '149.0' '89.00' '63.00' '48.00' '66.00' '139.0' '103.0'\n",
      " '125.0' '133.0' '138.0' '135.0' '142.0' '77.00' '62.00' '132.0' '84.00'\n",
      " '64.00' '74.00' '116.0' '82.00']\n"
     ]
    }
   ],
   "source": [
    "print(df['horsepower'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 엔진 출력이 문자열로 저장된 이유는 'horsepower' 열의 고유값을 출력해 보면 알 수 있다.\n",
    "* 고유값 중에 문자 '?'가 섞여 있어서 CSV 파일을 데이터프레임으로 변환하는 과정에서 문자열로 인식된 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)    # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)    # 누락 데이터 행 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')    # 문자열을 실수형으로 변환\n",
    "\n",
    "# horsepower 열의 자료형 확인\n",
    "print(df['horsepower'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2]\n",
      "['USA' 'JPN' 'EU']\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# 'origin' 열에는 정수형 데이터 1,2,3이 들어있지만, 실제로는 국가이름인 'USA,EU,JPN'을 뜻한다.\n",
    "print(df['origin'].unique())\n",
    "\n",
    "df['origin'].replace({1:'USA',2:'EU',3:'JPN'}, inplace=True)\n",
    "\n",
    "print(df['origin'].unique())\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "df['origin'] = df['origin'].astype('category')\n",
    "print(df['origin'].dtypes)\n",
    "\n",
    "df['origin'] = df['origin'].astype('str')\n",
    "print(df['origin'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319    80\n",
      "101    73\n",
      "371    82\n",
      "Name: model year, dtype: int64\n",
      "196    76\n",
      "380    82\n",
      "138    74\n",
      "Name: model year, dtype: category\n",
      "Categories (13, int64): [70, 71, 72, 73, ..., 79, 80, 81, 82]\n"
     ]
    }
   ],
   "source": [
    "# model year 열의 정수형을 범주형으로 변환\n",
    "# sample() 메소드로 'model year'열에서 무작위로 3개의 행을 선택해서 출력해본다.\n",
    "print(df['model year'].sample(3))\n",
    "df['model year'] = df['model year'].astype('category')\n",
    "print(df['model year'].sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 범주형(카테고리) 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. 구간 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 46.         107.33333333 168.66666667 230.        ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)    # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)    # 누락 데이터 행 삭제\n",
    "df['horsepower'] = df['horsepower'].astype('float')    # 문자열을 실수형으로 변환\n",
    "\n",
    "# np.histogram 함수로 3개의 bin으로 구분할 경계값의 리스트 구하기\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'horsepower' 열은 엔진 출력을 나타낸다.\n",
    "* 경우에 따라서는 엔진 출력을 숫자로 표시하는 대신 '저출력', '보통출력', '고출력' 등 구간으로 나누어서 표시하는 것이 효율적일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    horsepower hp_bin\n",
      "0        130.0   보통출력\n",
      "1        165.0   보통출력\n",
      "2        150.0   보통출력\n",
      "3        150.0   보통출력\n",
      "4        140.0   보통출력\n",
      "5        198.0    고출력\n",
      "6        220.0    고출력\n",
      "7        215.0    고출력\n",
      "8        225.0    고출력\n",
      "9        190.0    고출력\n",
      "10       170.0    고출력\n",
      "11       160.0   보통출력\n",
      "12       150.0   보통출력\n",
      "13       225.0    고출력\n",
      "14        95.0    저출력\n"
     ]
    }
   ],
   "source": [
    "bin_names = ['저출력','보통출력','고출력']\n",
    "\n",
    "# pd.cut 함수로 각 데이터를 3개의 bin에 할당\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],\n",
    "                      bins=bin_dividers,\n",
    "                      labels=bin_names,\n",
    "                      include_lowest=True)    # include_lowest=True 옵션을 사용하면 각 구간의 낮은 경계값을 포함한다.\n",
    "\n",
    "print(df[['horsepower','hp_bin']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-2. 더미 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 범주형 데이터를 컴퓨터가 인식할 수 있도록 숫자 0과 1로만 구성되는 원핫벡터(one hot vector)로 변환한다고 해서 원핫인코딩(one-hot-encoding)이라고도 부른다.\n",
    "* get_dummies() 함수를 사용하면, 범주형 변수의 모든 고유값을 각각 새로운 더미 변수로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    저출력  보통출력  고출력\n",
      "0     0     1    0\n",
      "1     0     1    0\n",
      "2     0     1    0\n",
      "3     0     1    0\n",
      "4     0     1    0\n",
      "5     0     0    1\n",
      "6     0     0    1\n",
      "7     0     0    1\n",
      "8     0     0    1\n",
      "9     0     0    1\n",
      "10    0     0    1\n",
      "11    0     1    0\n",
      "12    0     1    0\n",
      "13    0     0    1\n",
      "14    1     0    0\n"
     ]
    }
   ],
   "source": [
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "\n",
    "bin_names = ['저출력','보통출력','고출력']\n",
    "\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'],\n",
    "                      bins=bin_dividers,\n",
    "                      labels=bin_names,\n",
    "                      include_lowest=True)\n",
    "\n",
    "horsepower_dummies = pd.get_dummies(df['hp_bin'])\n",
    "print(horsepower_dummies.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2]\n",
      "<class 'numpy.ndarray'>\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]]\n",
      "<class 'numpy.ndarray'>\n",
      "  (0, 1)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (5, 0)\t1.0\n",
      "  (6, 0)\t1.0\n",
      "  (7, 0)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (10, 0)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (13, 0)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리를 이용해서 원핫인코딩을 편하게 처리할 수 있다.\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()    # label encoder 생성\n",
    "onehot_encoder = preprocessing.OneHotEncoder()    # one hot encoder 생성\n",
    "\n",
    "onehot_labeled = label_encoder.fit_transform(df['hp_bin'].head(15))\n",
    "print(onehot_labeled)\n",
    "print(type(onehot_labeled))\n",
    "\n",
    "# 2차원 행렬로 변경\n",
    "onehot_reshaped = onehot_labeled.reshape(len(onehot_labeled),1)\n",
    "print(onehot_reshaped)\n",
    "print(type(onehot_reshaped))\n",
    "\n",
    "# 희소행렬로 변환\n",
    "# 희소행렬은 (행,열)좌표와 값 형태로 정리된다.\n",
    "onehot_fitted = onehot_encoder.fit_transform(onehot_reshaped)\n",
    "print(onehot_fitted)\n",
    "print(type(onehot_fitted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 정규화\n",
    "* 각 열(변수)에 속하는 데이터 값을 동일한 크기 기준으로 나눈 비율로 나타내는 것을 정규화(normalization)라고 한다.\n",
    "* 정규화 과정을 거친 데이터의 범위는 '0에서 1' 또는 '-1에서 1'이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 방법1 - 각 열(변수)의 데이터를 해당 열의 최대값(의 절대값)으로 나누는 방법\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# horsepower 열의 통계 요약 정보로 최대값(max) 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "df.horsepower = df.horsepower/abs(df.horsepower.max())\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    392.000000\n",
      "mean     104.469388\n",
      "std       38.491160\n",
      "min       46.000000\n",
      "25%       75.000000\n",
      "50%       93.500000\n",
      "75%      126.000000\n",
      "max      230.000000\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "0    0.456522\n",
      "1    0.646739\n",
      "2    0.565217\n",
      "3    0.565217\n",
      "4    0.510870\n",
      "Name: horsepower, dtype: float64\n",
      "\n",
      "\n",
      "count    392.000000\n",
      "mean       0.317768\n",
      "std        0.209191\n",
      "min        0.000000\n",
      "25%        0.157609\n",
      "50%        0.258152\n",
      "75%        0.434783\n",
      "max        1.000000\n",
      "Name: horsepower, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 정규화 방법2 - 각 열 데이터에서 해당 열의 최소값을 뺀 값을 분자로 하고, 해당 열의 최대값과 최소값의 차를 분모로 하는 수를 계산하면 가장 큰 값은 역시 1이 된다.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./auto-mpg.csv', header=None)\n",
    "\n",
    "df.columns = ['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','name']\n",
    "\n",
    "df['horsepower'].replace('?', np.nan, inplace=True)\n",
    "df.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "df['horsepower'] = df['horsepower'].astype('float')\n",
    "\n",
    "# horsepower 열의 통계 요약 정보로 최대값(max)과 최소값(min) 확인\n",
    "print(df.horsepower.describe())\n",
    "print('\\n')\n",
    "\n",
    "# horsepower 열의 최대값의 절대값으로 모든 데이터를 나눠서 저장\n",
    "min_x = df.horsepower - df.horsepower.min()\n",
    "min_max = df.horsepower.max() - df.horsepower.min()\n",
    "df.horsepower = min_x/min_max\n",
    "\n",
    "print(df.horsepower.head())\n",
    "print('\\n')\n",
    "print(df.horsepower.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 시계열 데이터\n",
    "* 주식, 환율 등 금융 데이터를 다루기 위해 개발된 판다스는 시계열(time series) 데이터를 다루는 여러 가지 유용한 기능을 제공한다.\n",
    "* 특시 시계열 데이터를 데이터프레임의 행 인덱스로 사용하면, 시간으로 기록된 데이터를 분석하는 것이 매우 편리하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-1. 다른 자료형을 시계열 객체로 변환\n",
    "* 문자열을 Timestamp로 변환\n",
    "* 판다스 to_datetime() 함수를 사용하면 문자열 등 다른 자료형을 판다스 Timestamp를 나타내는 datetime64 자료형으로 변환 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume\n",
      "0  2018-07-02  10100  10850  10900  10000  137977\n",
      "1  2018-06-29  10700  10550  10900   9990  170253\n",
      "2  2018-06-28  10400  10900  10950  10150  155769\n",
      "3  2018-06-27  10900  10800  11050  10500  133548\n",
      "4  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    20 non-null     object\n",
      " 1   Close   20 non-null     int64 \n",
      " 2   Start   20 non-null     int64 \n",
      " 3   High    20 non-null     int64 \n",
      " 4   Low     20 non-null     int64 \n",
      " 5   Volume  20 non-null     int64 \n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 문자열을 Timestamp로 변환\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./stock-data.csv')\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      20 non-null     object        \n",
      " 1   Close     20 non-null     int64         \n",
      " 2   Start     20 non-null     int64         \n",
      " 3   High      20 non-null     int64         \n",
      " 4   Low       20 non-null     int64         \n",
      " 5   Volume    20 non-null     int64         \n",
      " 6   new_Date  20 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 1.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# 문자열 데이터(시리즈 객체)를 판다스 Timestamp로 변환\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])    # df에 새로운 열로 추가\n",
    "\n",
    "# 데이터 내용 및 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "print(type(df['new_Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close  Start   High    Low  Volume\n",
      "new_Date                                      \n",
      "2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2018-07-02 to 2018-06-01\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Close   20 non-null     int64\n",
      " 1   Start   20 non-null     int64\n",
      " 2   High    20 non-null     int64\n",
      " 3   Low     20 non-null     int64\n",
      " 4   Volume  20 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 960.0 bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 시계열 값으로 변환된 열을 새로운 행 인덱스로 지정. 기존 날짜 열은 삭제\n",
    "df.set_index('new_Date', inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# 데이터 내용 및 자료형 확인\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='datetime64[ns]', freq=None)\n",
      "\n",
      "\n",
      "PeriodIndex(['2019-01-01', '2020-03-01', '2021-06-01'], dtype='period[D]')\n",
      "PeriodIndex(['2019-01', '2020-03', '2021-06'], dtype='period[M]')\n",
      "PeriodIndex(['2019', '2020', '2021'], dtype='period[A-DEC]')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp를 Period로 변환\n",
    "# 판다스 to_period() 함수를 이용하면 일정한 기간을 나타내는 Period 객체로 Timestamp 객체를 변환할 수 있다.\n",
    "import pandas as pd\n",
    "\n",
    "# 날짜 형식의 문자열로 구성되는 리스트 정의\n",
    "dates = ['2019-01-01', '2020-03-01', '2021-06-01']\n",
    "\n",
    "# 문자열의 배열(시리즈 객체)을 판다스 Timestamp로 변환\n",
    "ts_dates = pd.to_datetime(dates)\n",
    "print(ts_dates)\n",
    "print('\\n')\n",
    "\n",
    "pr_day = ts_dates.to_period(freq='D')\n",
    "print(pr_day)\n",
    "pr_month = ts_dates.to_period(freq='M')\n",
    "print(pr_month)\n",
    "pr_year = ts_dates.to_period(freq='A')\n",
    "print(pr_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DatetimeIndex가 PeriodIndex로 변환되고, 자료형은 datetime64에서 period으로 변환된다.\n",
    "* freq 옵션을 'D'로 지정할 경우 1일의 기간을 나타내고, 'M'은 1개월의 기간을 뜻한다.\n",
    "* 'A'는 1년의 기간을 나타내는데, 1년이 끝나는 12월을 기준으로 삼는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-2. 시계열 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-01 00:00:00+09:00', '2019-02-01 00:00:00+09:00',\n",
      "               '2019-03-01 00:00:00+09:00', '2019-04-01 00:00:00+09:00',\n",
      "               '2019-05-01 00:00:00+09:00', '2019-06-01 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='MS')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp 배열 만들기\n",
    "import pandas as pd\n",
    "\n",
    "# Timestamp의 배열 만들기 - 월 간격, 월의 시작일 기준\n",
    "ts_ms = pd.date_range(start='2019-01-01',    # 날짜 범위 시작\n",
    "                      end=None,    # 날짜 범위 끝\n",
    "                      periods=6,    # 생성할 Timestamp 개수\n",
    "                      freq='MS',    # 시간 간격(MS: 월의 시작일)\n",
    "                      tz='Asia/Seoul')    # 시간대(timezone)\n",
    "print(ts_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-02-28 00:00:00+09:00',\n",
      "               '2019-03-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-05-31 00:00:00+09:00', '2019-06-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='M')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp의 배열 만들기 - 월 간격, 월의 마지막 날 기준\n",
    "ts_me = pd.date_range('2019-01-01', periods=6,\n",
    "                      freq='M',    # 시간 간격(M: 월의 마지막 날)\n",
    "                      tz='Asia/Seoul')    # 시간대(timezone)\n",
    "print(ts_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-31 00:00:00+09:00', '2019-04-30 00:00:00+09:00',\n",
      "               '2019-07-31 00:00:00+09:00', '2019-10-31 00:00:00+09:00',\n",
      "               '2020-01-31 00:00:00+09:00', '2020-04-30 00:00:00+09:00'],\n",
      "              dtype='datetime64[ns, Asia/Seoul]', freq='3M')\n"
     ]
    }
   ],
   "source": [
    "# Timestamp의 배열 만들기 - 분기(3개월) 간격, 월의 마지막 날 기준\n",
    "ts_3m = pd.date_range('2019-01-01', periods=6,\n",
    "                      freq='3M',    # 시간 간격(3M: 3개월)\n",
    "                      tz='Asia/Seoul')    # 시간대(timezone)\n",
    "print(ts_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2019-01', '2019-02', '2019-03'], dtype='period[M]')\n"
     ]
    }
   ],
   "source": [
    "# Period 배열\n",
    "# 판다스 period_range() 함수는 여러 개의 기간(Period)이 들어있는 시계열 데이터를 만든다.\n",
    "import pandas as pd\n",
    "\n",
    "# Period 배열 만들기 - 1개월 길이\n",
    "pr_m = pd.period_range(start='2019-01-01',\n",
    "                       end=None,\n",
    "                       periods=3,\n",
    "                       freq='M')\n",
    "print(pr_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6-3. 시계열 데이터 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26\n",
      "\n",
      "\n",
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  Day\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7    2\n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   29\n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   28\n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   27\n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   26\n"
     ]
    }
   ],
   "source": [
    "# 날짜 데이터 분리\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('stock-data.csv')\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])    # df에 새로운 열로 추가\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "# dt 속성을 이용해서 new_Date 열의 연-월-일 정보를 년,월,일로 구분\n",
    "df['Year'] = df['new_Date'].dt.year\n",
    "df['Month'] = df['new_Date'].dt.month\n",
    "df['Day'] = df['new_Date'].dt.day\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Close  Start   High    Low  Volume   new_Date  Year  Month  \\\n",
      "0  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018      7   \n",
      "1  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018      6   \n",
      "2  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018      6   \n",
      "3  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018      6   \n",
      "4  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018      6   \n",
      "\n",
      "   Day Date_yr   Date_m  \n",
      "0    2    2018  2018-07  \n",
      "1   29    2018  2018-06  \n",
      "2   28    2018  2018-06  \n",
      "3   27    2018  2018-06  \n",
      "4   26    2018  2018-06  \n"
     ]
    }
   ],
   "source": [
    "# Timestamp를 Period로 변환하여 연-월-일 표기 변경하기\n",
    "df['Date_yr'] = df['new_Date'].dt.to_period(freq='A')\n",
    "df['Date_m'] = df['new_Date'].dt.to_period(freq='M')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date  Close  Start   High    Low  Volume   new_Date  Year  \\\n",
      "Date_m                                                                     \n",
      "2018-07  2018-07-02  10100  10850  10900  10000  137977 2018-07-02  2018   \n",
      "2018-06  2018-06-29  10700  10550  10900   9990  170253 2018-06-29  2018   \n",
      "2018-06  2018-06-28  10400  10900  10950  10150  155769 2018-06-28  2018   \n",
      "2018-06  2018-06-27  10900  10800  11050  10500  133548 2018-06-27  2018   \n",
      "2018-06  2018-06-26  10800  10900  11000  10700   63039 2018-06-26  2018   \n",
      "\n",
      "         Month  Day Date_yr  \n",
      "Date_m                       \n",
      "2018-07      7    2    2018  \n",
      "2018-06      6   29    2018  \n",
      "2018-06      6   28    2018  \n",
      "2018-06      6   27    2018  \n",
      "2018-06      6   26    2018  \n"
     ]
    }
   ],
   "source": [
    "# 원하는 열을 새로운 행 인덱스로 지정\n",
    "df.set_index('Date_m', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "DatetimeIndex(['2018-07-02', '2018-06-29', '2018-06-28', '2018-06-27',\n",
      "               '2018-06-26', '2018-06-25', '2018-06-22', '2018-06-21',\n",
      "               '2018-06-20', '2018-06-19', '2018-06-18', '2018-06-15',\n",
      "               '2018-06-14', '2018-06-12', '2018-06-11', '2018-06-08',\n",
      "               '2018-06-07', '2018-06-05', '2018-06-04', '2018-06-01'],\n",
      "              dtype='datetime64[ns]', name='new_Date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스 활용\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('stock-data.csv')\n",
    "\n",
    "df['new_Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('new_Date', inplace=True)    # 행 인덱스로 지정\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "2018-06-29  2018-06-29  10700  10550  10900   9990  170253\n",
      "2018-06-28  2018-06-28  10400  10900  10950  10150  155769\n",
      "2018-06-27  2018-06-27  10900  10800  11050  10500  133548\n",
      "2018-06-26  2018-06-26  10800  10900  11000  10700   63039\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n",
      "            Start   High\n",
      "new_Date                \n",
      "2018-07-02  10850  10900\n",
      "\n",
      "\n",
      "                  Date  Close  Start   High    Low  Volume\n",
      "new_Date                                                  \n",
      "2018-07-02  2018-07-02  10100  10850  10900  10000  137977\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Date, Close, Start, High, Low, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-ff33fcd2c53c>:2: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  df_y = df['2018']\n",
      "<ipython-input-27-ff33fcd2c53c>:11: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  df_ymd = df['2018-07-02']\n"
     ]
    }
   ],
   "source": [
    "# 날짜 인덱스를 이용하여 데이터 선택하기\n",
    "df_y = df['2018']\n",
    "print(df_y.head())\n",
    "print('\\n')\n",
    "df_ym = df.loc['2018-07']\n",
    "print(df_ym)\n",
    "print('\\n')\n",
    "df_ym_cols = df.loc['2018-07','Start':'High']    # 열 범위 슬라이싱\n",
    "print(df_ym_cols)\n",
    "print('\\n')\n",
    "df_ymd = df['2018-07-02']\n",
    "print(df_ymd)\n",
    "print('\\n')\n",
    "df_ymd_range = df['2018-06-25':'2018-06-20']\n",
    "print(df_ymd_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 날짜 인덱스를 사용하는 장점은 연-월-일 중에서 내가 필요로 하는 레벨을 선택적으로 인덱싱할 수 있다는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date  Close  Start   High    Low  Volume\n",
      "time_delta                                                \n",
      "180 days    2018-06-28  10400  10900  10950  10150  155769\n",
      "181 days    2018-06-27  10900  10800  11050  10500  133548\n",
      "182 days    2018-06-26  10800  10900  11000  10700   63039\n",
      "183 days    2018-06-25  11150  11400  11450  11000   55519\n",
      "186 days    2018-06-22  11300  11250  11450  10750  134805\n",
      "187 days    2018-06-21  11200  11350  11750  11200  133002\n",
      "188 days    2018-06-20  11550  11200  11600  10900  308596\n",
      "189 days    2018-06-19  11300  11850  11950  11300  180656\n"
     ]
    }
   ],
   "source": [
    "# 시간 간격 계산. 최근 180일에서 189일 사이의 값들만 선택하기\n",
    "today = pd.to_datetime('2018-12-25')\n",
    "df['time_delta'] = today - df.index\n",
    "df.set_index('time_delta', inplace=True)\n",
    "df_180 = df['180 days':'189 days']\n",
    "print(df_180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
